# -*- coding: utf-8 -*-
"""
update_recommendations.py

1. OpenAI ã§æŠ•ç¨¿åŸ‹ã‚è¾¼ã¿ã‚’è£œå®Œï¼ˆæœªç”ŸæˆæŠ•ç¨¿ã®ã¿ï¼‰
2. AttentionPooling ã§ UserEmbedding ã‚’å†ç”Ÿæˆ
3. FollowPredictor ã§æ¨è–¦ã‚’å†è¨ˆç®—ï¼ˆæ—§æ¨è–¦ã‚’å…¨å‰Šé™¤ â†’ ä¸Šä½ k ä»¶ä¿å­˜ï¼‰
"""

import os, time, numpy as np, torch, torch.nn as nn, torch.nn.functional as F
from django.core.management.base import BaseCommand
from django.conf import settings
from django.contrib.auth import get_user_model
from posts.models import Post                      # æŠ•ç¨¿æœ¬ä½“
from recommendations.models import (               # åŸ‹ã‚è¾¼ã¿ & æ¨è–¦
    PostEmbedding, UserEmbedding, UserRecommendation
)

# â”€â”€â”€â”€â”€ ç·¨é›†ãƒã‚¤ãƒ³ãƒˆ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
OPENAI_API_KEY = ""               # ã“ã“ã« sk-xxxx ã‚’è²¼ã‚‹ï¼ˆç©ºãªã‚‰ç’°å¢ƒå¤‰æ•°ã‚’ä½¿ç”¨ï¼‰
EMBED_MODEL    = "text-embedding-3-large"
BATCH_SIZE_EMB = 32               # OpenAI å‘¼ã³å‡ºã—ã®ãƒãƒƒãƒã‚µã‚¤ã‚º
# â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

if not OPENAI_API_KEY:
    OPENAI_API_KEY = os.getenv("OPENAI_API_KEY", "")
if OPENAI_API_KEY:
    import openai
    openai.api_key = OPENAI_API_KEY
else:
    print("[WARNING] OPENAI_API_KEY ãŒè¨­å®šã•ã‚Œã¦ã„ãªã„ãŸã‚ã€æŠ•ç¨¿åŸ‹ã‚è¾¼ã¿è£œå®Œã¯ã‚¹ã‚­ãƒƒãƒ—ã•ã‚Œã¾ã™ã€‚")

User = get_user_model()
NODE2VEC_DIM, OPENAI_DIM, MAX_POSTS = 128, 3072, 50

# -------------------------- ãƒ¢ãƒ‡ãƒ«å®šç¾© --------------------------
class AttentionPooling(nn.Module):
    def __init__(self, post_dim=OPENAI_DIM, acc_dim=NODE2VEC_DIM, n_head=8):
        super().__init__()
        self.mha  = nn.MultiheadAttention(post_dim, n_head, batch_first=True, dropout=0.1)
        self.ln   = nn.LayerNorm(post_dim)
        self.proj = nn.Sequential(nn.Linear(post_dim, acc_dim*2), nn.GELU(),
                                  nn.Linear(acc_dim*2, acc_dim))
        self.sc   = nn.Linear(post_dim, 1, bias=False)

    def forward(self, x, mask=None):
        x  = nn.functional.normalize(x, p=2, dim=-1)
        att,_ = self.mha(x, x, x, key_padding_mask=(mask==0) if mask is not None else None)
        x  = self.ln(x + att)
        scr = self.sc(x).squeeze(-1)
        if mask is not None:
            scr = scr.masked_fill(mask == 0, -1e9)
        w   = nn.functional.softmax(scr, dim=-1)
        acc = torch.sum(x * w.unsqueeze(-1), dim=1)
        return nn.functional.normalize(self.proj(acc), p=2, dim=-1)

class FollowPredictor(nn.Module):
    def __init__(self, dim=NODE2VEC_DIM, hid=256):
        super().__init__()
        self.fe = nn.Sequential(nn.Linear(dim, hid), nn.GELU())
        self.te = nn.Sequential(nn.Linear(dim, hid), nn.GELU())
        self.head = nn.Sequential(
            nn.Linear(hid*3, hid), nn.GELU(),
            nn.Linear(hid, hid//2), nn.GELU(),
            nn.Linear(hid//2, 1), nn.Sigmoid()
        )
    def forward(self, f, t):
        f, t = self.fe(f), self.te(t)
        return self.head(torch.cat([f, t, f*t], -1)).squeeze(-1)

class EndToEndFollowModel(nn.Module):
    def __init__(self):
        super().__init__()
        self.attention_pooling = AttentionPooling()
        self.follow_predictor  = FollowPredictor()

# -------------------------- ã‚³ãƒãƒ³ãƒ‰ --------------------------
class Command(BaseCommand):
    help = "OpenAIåŸ‹ã‚è¾¼ã¿â†’UserEmbeddingâ†’æ¨è–¦ã‚’ä¸€æ‹¬æ›´æ–°"

    def add_arguments(self, parser):
        parser.add_argument("--force", action="store_true",
                            help="æ—¢å­˜ UserEmbedding ã‚’å‰Šé™¤ã—ã¦å®Œå…¨å†ç”Ÿæˆ")
        parser.add_argument("--top_k", type=int, default=10,
                            help="ä¿å­˜ã™ã‚‹æ¨è–¦ä¸Šä½ä»¶æ•°")

    def log(self, msg): self.stdout.write(msg)

    # ---------- STEP 1: æŠ•ç¨¿åŸ‹ã‚è¾¼ã¿è£œå®Œ ----------
    def rebuild_post_embeddings(self):
        if not OPENAI_API_KEY:
            self.log("ğŸ” STEP1: ã‚­ãƒ¼ãªã— â†’ è£œå®Œã‚’ã‚¹ã‚­ãƒƒãƒ—")
            return

        qs = Post.objects.filter(embedding__isnull=True).values("id", "content")
        total = qs.count()
        self.log(f"ğŸ” STEP1: æœªåŸ‹ã‚è¾¼ã¿æŠ•ç¨¿ = {total}")

        ids, texts, done = [], [], 0
        for rec in qs.iterator():
            ids.append(rec["id"]); texts.append(rec["content"])
            if len(ids) == BATCH_SIZE_EMB:
                done += self._embed_batch(ids, texts)
                ids, texts = [], []
        if ids:
            done += self._embed_batch(ids, texts)
        self.log(f"âœ… æŠ•ç¨¿åŸ‹ã‚è¾¼ã¿è£œå®Œ å®Œäº† ({done}/{total})")

    def _embed_batch(self, ids, texts):
        try:
            resp = openai.Embedding.create(model=EMBED_MODEL, input=texts)
            for pid, item in zip(ids, resp["data"]):
                post = Post.objects.get(id=pid)
                PostEmbedding.objects.update_or_create(
                    post=post,
                    defaults={"vector": item["embedding"]}
                )
            return len(ids)
        except Exception as e:
            self.log(f"[ERROR] OpenAI åŸ‹ã‚è¾¼ã¿å¤±æ•—: {e}")
            return 0

    # ---------- STEP 2: UserEmbedding ç”Ÿæˆ ----------
    def rebuild_user_embeddings(self, model, device, force):
        if force:
            cnt = UserEmbedding.objects.count()
            UserEmbedding.objects.all().delete()
            self.log(f"ğŸ—‘ï¸ æ—§ UserEmbedding {cnt} ä»¶ã‚’å‰Šé™¤ (--force)")

        users = User.objects.filter(is_staff=False, is_superuser=False)
        total = users.count()
        self.log(f"ğŸ” STEP2: UserEmbedding ç”Ÿæˆ å¯¾è±¡ {total} äºº")

        for idx, u in enumerate(users, 1):
            vecs = [np.array(pe.vector, np.float32)
                    for pe in PostEmbedding.objects.filter(post__user=u)
                    if pe.vector and len(pe.vector)==OPENAI_DIM]
            if not vecs: continue
            arr, mask = self._pad(vecs)
            with torch.no_grad():
                acc = model.attention_pooling(
                    torch.tensor(arr).unsqueeze(0).to(device),
                    torch.tensor(mask).unsqueeze(0).to(device)).cpu().squeeze(0)
            UserEmbedding.objects.update_or_create(
                user=u, defaults={"node2vec_vector": acc.tolist()})
            if idx <= 3:
                self.log(f"  -> {u.username} æ›´æ–°")
        self.log("âœ… UserEmbedding ç”Ÿæˆ å®Œäº†")

    def _pad(self, vecs):
        n = min(len(vecs), MAX_POSTS)
        arr  = np.zeros((MAX_POSTS, OPENAI_DIM), np.float32)
        mask = np.zeros(MAX_POSTS, np.float32)
        arr[:n]  = vecs[:n]
        mask[:n] = 1
        return arr, mask

    # ---------- STEP 3: æ¨è–¦å†è¨ˆç®— ----------
    def rebuild_recommendations(self, model, device, top_k):
        UserRecommendation.objects.all().delete()
        self.log("ğŸ—‘ï¸ æ—§æ¨è–¦ å…¨å‰Šé™¤")

        vec_map = {str(e.user_id): np.array(e.node2vec_vector, np.float32)
                   for e in UserEmbedding.objects.all()}
        users = list(vec_map.keys())

        for uid in users:
            cand = [c for c in users if c != uid]
            results = []
            for cid in cand:
                with torch.no_grad():
                    p = model.follow_predictor(
                            torch.tensor(vec_map[uid]).unsqueeze(0).to(device),
                            torch.tensor(vec_map[cid]).unsqueeze(0).to(device)).item()
                results.append((cid, p))
            for cid, p in sorted(results, key=lambda x: x[1], reverse=True)[:top_k]:
                UserRecommendation.objects.create(
                    user_id=uid, recommended_user_id=cid,
                    score=p, follow_probability=round(p*100, 1))
        self.log("âœ… æ¨è–¦å†è¨ˆç®— å®Œäº†")

    # ---------- ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ ----------
    def handle(self, *args, **opt):
        t0 = time.time()
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        self.log(f"ğŸ–¥ï¸ device = {device}")

        # 1. æŠ•ç¨¿åŸ‹ã‚è¾¼ã¿è£œå®Œ
        self.rebuild_post_embeddings()

        # 2. ãƒ¢ãƒ‡ãƒ«ãƒ­ãƒ¼ãƒ‰ï¼ˆå­¦ç¿’æ¸ˆã¿ã‚ã‚Œã°ï¼‰
        model = EndToEndFollowModel()
        ckpt_path = os.path.join(settings.BASE_DIR,
                                 "recommendations", "pretrained",
                                 "attention_pooling_follow_model.pt")
        if os.path.exists(ckpt_path):
            ckpt = torch.load(ckpt_path, map_location="cpu")
            ckpt = {k.replace("ap.", "attention_pooling.").replace("fp.", "follow_predictor."): v
                    for k, v in ckpt.items()}
            model.load_state_dict(ckpt, strict=False)
        model.to(device).eval()

        # 3. UserEmbedding â†’ æ¨è–¦
        self.rebuild_user_embeddings(model, device, opt["force"])
        self.rebuild_recommendations(model, device, opt["top_k"])

        self.log(f"ğŸ‰ ALL DONE in {time.time()-t0:.1f}s")